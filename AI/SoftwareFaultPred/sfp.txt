ABSTRACT Software fault prediction is a critical aspect of software engineering aimed at improving software quality and reliability. However, it faces significant challenges, including the class imbalance issue in fault data and the need for robust predictive models that generalize well across different projects. In this research, we delve into these challenges and investigate the impact of class imbalance and model generalization on software fault prediction using cross-project analysis. Our study addresses three primary research questions: Firstly, we examine the critical issue of class imbalance in fault prediction, which poses a significant hurdle to accurate model performance. Through extensive experimentation with various classifiers on diverse datasets from different software projects, we highlight the variations in classifier performance and the necessity of addressing class imbalance for reliable predictions. Secondly, we evaluate the reliability of cross-project prediction, aiming to understand how effectively predictive models trained on one project can generalize to predict faults in other projects. We demonstrate the importance of training with datasets sharing similar characteristics with the target project for achieving reliable cross-project prediction. Thirdly, we analyze the impact of increasing training samples from different projects on prediction accuracy, emphasizing the benefits of utilizing cross-project analysis to enhance predictive model performance. In addition to addressing these research questions, we provide a comprehensive comparison of classifier performance metrics, including accuracy, precision, recall, and F1 Score. Our findings not only shed light on the challenges and opportunities in software fault prediction but also emphasize the importance of considering class imbalance and model generalization for developing robust and reliable fault prediction models. This research contributes to advancing the field by providing insights into effective modeling approaches and highlighting the motivation behind addressing these challenges.
INDEX TERMS Class Imbalance, Cross-Project Analysis, Machine Learning Classifiers, Model Generalization, Performance Metrics, Software Fault Prediction.
I.
INTRODUCTION
Software fault prediction plays a crucial role in software engineering, enabling the development of predictive models to identify potential defects in software systems [17]. Predicting faults at an early stage can lead to significant improvements in software quality, reduced maintenance costs, and enhanced overall reliability. However, the accurate prediction of software faults remains challenging due to the complex nature of software development and a class imbalance in software defect datasets [5].
Class imbalance refers to the situation where the number of defective samples (positive class) is significantly lower than the number of non-defective samples (negative class) in a given dataset [4]. In software fault prediction, software defects are generally infrequent compared to many defect-free instances, resulting in an imbalanced distribution. This class imbalance can adversely affect the performance of predictive models, leading to biased results and reduced accuracy [5].
In recent years, cross-project prediction has emerged as a technique to address the issue of limited resources and improve model generalization [8]. Cross-project software defect prediction (CPSDP) leverages historical defect data This article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and
content may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3397494
This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/
Author Name: Preparation of Papers for IEEE Access (February 2017)
2 VOLUME XX, 2017
from one or more completed software projects to predict potential flaws in new projects [9]. The methodology is based on the premise that patterns of faults observed in one project can be indicative of the possibility of errors in another.
Cross-project defect prediction offers several advantages, including the ability to transfer knowledge and experience from prior projects to enhance the quality of future software systems [9]. By using information from previous projects, developers can identify potential risk factors and allocate resources more effectively, thereby improving their products' overall quality and reliability [10].
While many machine learning algorithms, such as support vector machine, decision tree, neural networks, and naive Bayes, have been applied to within-project defect prediction, they often face the challenge of class imbalance [1]. Most training data typically consists of defect-free instances, making it difficult for the model to predict the minority class of faulty instances accurately. This class imbalance hinders the prediction ability of the models [6]. To tackle this issue, within-project class imbalance learning methods have been developed, with sampling techniques being one of the most widely used approaches [4]. These methods utilize undersampling or oversampling techniques to transform the class-imbalanced project into a balanced one, thereby improving the performance of predictive models [6].
A.
RESEARCH QUESTIONS
This paper investigates the behavior of five NASA datasets (JM1, CM1, KC1, KC2, PC1) to explore the feasibility of cross-project learning and individual dataset effectiveness. We conduct various analyses, including performance checks before and after class imbalance handling, performance evaluation by training with one dataset and testing with another, and assessing the impact of increasing training samples while testing with different datasets.
FIGURE 1.
Framework for Cross-Project Defect Prediction
As mentioned in Figure 1, we consider Project A to be the source project and Project B to be the target project. We apply class imbalance handling to both projects (A* and B*) and use A* as the training set and B* as the test set. We then build prediction models on A* and test them on B*, obtaining the cross-project defect prediction results.
To achieve the objectives of this study, we address the following research questions:
RQ-1: Is class imbalance a critical issue in software fault prediction? To answer this question, we investigate the effects of class imbalance on fault prediction accuracy. We compare the performance of predictive models trained on balanced and imbalanced datasets, evaluating how class distribution impacts the accuracy of fault prediction.
RQ-2: Does cross-project prediction demonstrate reliable performance in software fault prediction? To assess the effectiveness of cross-project prediction, we train predictive models on one project and test them on data from other projects. By analyzing the performance across different projects, we explore the potential of cross-project prediction in improving model generalization. For this analysis, we train the models with oversampled datasets and test them with undersampled datasets to gain insights into model generalization and robustness.
RQ-3: Does increasing training samples from different projects increase the accuracy of fault prediction? In this research question, we investigate the impact of increasing the training sample size by combining data from other projects. We create various combinations of oversampled datasets and evaluate their performance on undersampled datasets to understand the benefits of combined training samples.
The primary contribution of this research is to provide a comprehensive analysis of class imbalance and cross-project prediction in software fault prediction. By addressing the research questions, we aim to uncover the challenges posed by class imbalance and explore the potential of cross-project prediction to enhance the accuracy and generalization of predictive models.
This paper is structured as follows: Section 2 provides a related work on software fault prediction, class imbalance handling, and cross-project prediction. Section 3 details the methodology, including datasets, classifiers, parameter tuning, and evaluation metrics. Section 4 presents the results of the experiments conducted for each research question. Section 5 discusses the implications of the findings, and Section 6 concludes the research with a summary of key insights.
II.
Related Work
Software fault prediction has been an active research area in software engineering, aiming to develop effective predictive models for identifying potential defects in software systems. Within the realm of software fault prediction, two key aspects that have garnered significant attention are class imbalance handling and cross-project prediction. In this section, we present a comprehensive literature survey that provides an overview of existing approaches and techniques related to software fault prediction while highlighting the challenges posed by class imbalance and the potential benefits of cross-
This article has been accepted for publication in IEEE Access. This is the author's version which has not been fully edited and
content may change prior to final publication. Citation information: DOI 10.1109/ACCESS.2024.3397494
This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/
Author Name: Preparation of Papers for IEEE Access (February 2017)
2 VOLUME XX, 2017
project prediction in improving model generalization and performance.
A.
SOFTWARE FAULT PREDICTION
Traditional software fault prediction methods have primarily focused on within-project software defect prediction (WSDP) [1,2]. These methods involve building predictive models using historical data from a single project [3]. Various machine learning algorithms, such as support vector machines (SVM), decision trees, random forests, naive Bayes, and neural networks, have been widely applied to WSDP, aiming to achieve accurate predictions [17].
Mahajan et al. (2015) proposed a software fault prediction model using the Bayesian Regularization (BR) technique in their study. The authors leveraged Bayesian reasoning to construct the predictive model, which proved effective in identifying potential software defects [17].
Despite the success of these methods, one of the primary challenges in WSDP is the class imbalance issue, wherein the number of defective instances is substantially smaller than non-defective instances [5]. Several approaches have been proposed to address this issue. Chawla et al. (2004) introduced the concept of resampling techniques, including oversampling and undersampling, to balance the class distribution. Sun et al. (2007) explored cost-sensitive learning to tackle class imbalance by adjusting the misclassification costs of different classes [5].
More recent works, such as those by Kaliraj and Jaiswal (2019) and Manchala and Bisi (2022), have adopted advanced techniques like Generative Adversarial Networks (GANs) and diversity-based imbalance learning to improve the performance of predictive models in the presence of class imbalance [6, 7].
Brundha Elci J. and Nandagopalan S. (2024) proposed a novel weighted dual cross-recurrent network-based levy sparrow search (WDCRN-LSS) model for software fault prediction. The model accurately predicts the expected number of software faults in earlier phases of software projects, enhancing software quality and minimizing cost factors such as time, resources, and effort [32].
Yu T et al. (2019) presented ConPredictor, an approach to predict defects specific to concurrent programs. The approach combines static and dynamic program metrics, introducing novel static code metrics and leveraging dynamic metrics based on mutation analysis. It improves both within-project and cross-project defect prediction compared to traditional features [33].
Murillo-Morera J et al. (2016) reported the results of empirical studies using an automated genetic defect prediction framework. The framework generates and compares different learning schemes using a genetic algorithm to estimate the defect proneness of software modules, demonstrating similar performance between frameworks and better runtime compared to an exhaustive framework [34]. Arora R et al. (2022) introduced a framework for heterogeneous fault prediction (HFP) using feature selection and supervised learning algorithms. The approach significantly improves prediction performance for heterogeneous projects compared to cross projects, demonstrating the effectiveness of feature selection and supervised learning algorithms [35].
Kaliraj S et al. (2023) proposed an optimized feature selection process based on a genetic algorithm for software fault prediction. The approach employs the Random Over-sampling method to counter class imbalance. It examines software metric categories to identify influential metrics, demonstrating substantial improvements in prediction accuracy compared to traditional methods [36].
B.
CLASS IMBALANCE HANDLING IN SOFTWARE FAULT PREDICTION
Researchers have dedicated considerable efforts to exploring class imbalance handling techniques tailored explicitly for software fault prediction [20,21]. Resampling techniques have emerged as popular solutions to balance class distribution and enhance model performance [18, 19].
Chawla et al. (2002) introduced the SMOTE (Synthetic Minority Over-sampling Technique) method, which generates synthetic instances of the minority class to address class imbalance. He et al. (2008) extended SMOTE with ADASYN (Adaptive Synthetic Sampling), which adapts the oversampling process based on the local density of minority class instances, leading to better results [4, 5].
Furthermore, Zhang et al. (2015) explored the effectiveness of combining multiple classifiers to improve cross-project defect prediction. By combining classifiers, they achieved better prediction performance and enhanced robustness [15].
The study by Chen et al. (2018) emphasized tackling class overlap and imbalance problems in software defect prediction. They proposed a novel method to extract non-overlapping regions in feature space to improve model performance, especially in the presence of class imbalance and overlap [16].
Li et al. (2018) introduced a method for heterogeneous fault prediction using cost-sensitive domain adaptation. Their approach aimed to improve fault prediction accuracy across different software projects [37]. Limsettho et al. (2018) proposed a cross-project defect prediction technique employing class distribution estimation and oversampling. Their method aimed to enhance defect prediction performance by addressing class imbalance and project heterogeneity[38]. Wang et al. (2023) developed BugPre, an intelligent system for predicting software bugs across different versions using graph convolutional neural networks. Their approach demonstrated effectiveness in identifying potential bugs in software releases [39]. Kanwar et al. (2023) proposed a hybrid method for selecting candidate projects in cross-project defect prediction. Their approach aimed to improve the selection process by combining multiple techniques for better prediction accuracy [40]. Tahir et al. (2023) focused on early software defect density prediction using supervised learning on international software benchmarking cross-project data. Their